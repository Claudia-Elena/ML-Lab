{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.tree import DecisionTreeClassifier\n\n\ndef compute_the_naive_bayes() :\n    \n    # incarcare dataset\n    df = pd.read_csv(\"../input/spam-text-message-classification/SPAM text message 20170820 - Data.csv\")  \n    cv = CountVectorizer()\n    \n    # stocheaza matricea de caracteristici (X) si vectorul de raspuns (y)\n    \n    X = cv.fit_transform(df['Message']).toarray()  \n    \n    # impartim X si y in train set si test set\n    X_train, X_test, y_train, y_test = train_test_split(X, df.Category, test_size=0.2,\n                                                        random_state=32)  \n    var = X_train.shape, X_test.shape, y_train.shape, y_test.shape\n    \n    # antrenarea modelului pe train set\n    nb = MultinomialNB().fit(X_train, y_train) \n    \n    # facem predictia pe test set\n    pred_nb = nb.predict(X_test)  \n\n    # comparam valorile reale de raspuns (y_test) cu valorile de raspuns prezise (y_pred)\n    print('Naive Bayes score is : %{acc}', accuracy_score(y_test, pred_nb) * 100) \n    print(classification_report(y_test, pred_nb))\n    \n    # antrenarea modelului pe train set\n    dec = DecisionTreeClassifier().fit(X_train, y_train)\n    \n    # predictia pe test set\n    pred_dec = dec.predict(X_test)  \n\n    # comparam valorile reale de raspuns (y_test) cu valorile de raspuns prezise (y_pred)\n    print('DecisionTree score is : %{acc}', accuracy_score(y_test, pred_nb) * 100) \n    print(classification_report(y_test, pred_dec))\n\nif __name__ == '__main__' :\n        compute_the_naive_bayes()\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-08T21:33:37.255898Z","iopub.execute_input":"2022-11-08T21:33:37.256312Z","iopub.status.idle":"2022-11-08T21:33:52.551163Z","shell.execute_reply.started":"2022-11-08T21:33:37.256279Z","shell.execute_reply":"2022-11-08T21:33:52.549695Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Naive Bayes score is : %{acc} 98.20627802690582\n              precision    recall  f1-score   support\n\n         ham       0.99      0.99      0.99       972\n        spam       0.94      0.92      0.93       143\n\n    accuracy                           0.98      1115\n   macro avg       0.97      0.95      0.96      1115\nweighted avg       0.98      0.98      0.98      1115\n\nDecisionTree score is : %{acc} 98.20627802690582\n              precision    recall  f1-score   support\n\n         ham       0.98      0.98      0.98       972\n        spam       0.89      0.90      0.89       143\n\n    accuracy                           0.97      1115\n   macro avg       0.94      0.94      0.94      1115\nweighted avg       0.97      0.97      0.97      1115\n\n","output_type":"stream"}]}]}